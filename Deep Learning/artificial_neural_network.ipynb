{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "artificial_neural_network.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP6JLo1tGNBg"
      },
      "source": [
        "# Artificial Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWZyYmS_UE_L"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxkJoQBkUIHC"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaTwK7ojXr2F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e2dca6f3-5ebe-4c88-c33f-54f823b7a212"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.6.0'"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E0Q3aoKUCRX"
      },
      "source": [
        "## Part 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKWAkFVGUU0Z"
      },
      "source": [
        "### Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXUkhkMfU4wq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e86664fa-0339-459c-f98e-81de16612b3e"
      },
      "source": [
        "dataset = pd.read_csv('Churn_Modelling.csv')\n",
        "X = dataset.iloc[:, 3:-1].values #x dataset; starting from 3rd column until the end BUT NOT the last one with the EXITED\n",
        "y = dataset.iloc[:, -1].values #y variable; the last column \n",
        "'''we don't need all columns, e.g. the customer ID or their surnames'''"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"we don't need all columns, e.g. the customer ID or their surnames\""
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYP9cQTWbzuI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a57aae16-1d51-497c-d359-d5190c37b9fa"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[619 'France' 'Female' ... 1 1 101348.88]\n",
            " [608 'Spain' 'Female' ... 0 1 112542.58]\n",
            " [502 'France' 'Female' ... 1 0 113931.57]\n",
            " ...\n",
            " [709 'France' 'Female' ... 0 1 42085.58]\n",
            " [772 'Germany' 'Male' ... 1 0 92888.52]\n",
            " [792 'France' 'Female' ... 1 0 38190.78]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38vKGE6Nb2RR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3caf3352-0d8f-471c-e880-34510e7ceb92"
      },
      "source": [
        "print(y) #the decision of the customer to leave the bank or not "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 1 ... 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6bQ0UgSU-NJ"
      },
      "source": [
        "### Encoding categorical data\n",
        "\n",
        "Converting categorical text data into model-understandable numerical data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le5MJreAbW52"
      },
      "source": [
        "Label Encoding the \"Gender\" column\n",
        "\n",
        "So we need to encode the gender column possibly into 0 and 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxVKWXxLbczC"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "X[:, 2] = le.fit_transform(X[:, 2]) #the gender column :, 2 meaning from the beginning till the 2nd column (the Gender one)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M1KboxFb6OO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6928366-9db0-4da8-8a20-fc21349b9f93"
      },
      "source": [
        "print(X) # female and male with 0 and 1, a random decision of the machine "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[619 'France' 0 ... 1 1 101348.88]\n",
            " [608 'Spain' 0 ... 0 1 112542.58]\n",
            " [502 'France' 0 ... 1 0 113931.57]\n",
            " ...\n",
            " [709 'France' 0 ... 0 1 42085.58]\n",
            " [772 'Germany' 1 ... 1 0 92888.52]\n",
            " [792 'France' 0 ... 1 0 38190.78]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUxGZezpbMcb"
      },
      "source": [
        "One Hot Encoding the \"Geography\" column\n",
        "\n",
        "We have three countries; France, Spain and Germany - we cannot use 0,1 and 2, the way we did with Gender. Why use OneHotEncoder: depending on the data we have, we might run into situations where, after label encoding, we might confuse our model into thinking that a column has data with some kind of order or hierarchy, when we clearly don’t have it. To avoid this, we ‘OneHotEncode’ that column. What is does is: it takes a column which has categorical data, which has been label encoded, and then splits the column into multiple columns. The numbers are replaced by 1s and 0s, depending on which column has what value. In our example, we’ll get three new columns, one for each country — France, Germany, and Spain."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMXC8-KMVirw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7822e67d-8077-4102-ef71-3d35423fad2b"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
        "X = np.array(ct.fit_transform(X))\n",
        "\n",
        "'changing the index of the column we want to transform'"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'changing the index of the column we want to transform'"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcxwEon-b8nV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "999cf525-265b-42af-df69-d4500d9cea01"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0 0.0 0.0 ... 1 1 101348.88]\n",
            " [0.0 0.0 1.0 ... 0 1 112542.58]\n",
            " [1.0 0.0 0.0 ... 1 0 113931.57]\n",
            " ...\n",
            " [1.0 0.0 0.0 ... 0 1 42085.58]\n",
            " [0.0 1.0 0.0 ... 1 0 92888.52]\n",
            " [1.0 0.0 0.0 ... 1 0 38190.78]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJTsUuPvNp7B"
      },
      "source": [
        "How the encoded column looks like now; the 1.0 0.0 1.0 is for France, 1.0 0.0 1.0 is for Spain and 0.0 1.0 0.0 is for Germany. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHol938cW8zd"
      },
      "source": [
        "### Splitting the dataset into the Training set and Test set\n",
        "\n",
        "Note: Setting random_state a fixed value will guarantee that same sequence of random numbers are generated each time you run the code. And unless there is some other randomness present in the process, the results produced will be same as always. This helps in verifying the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-TDt0Y_XEfc"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RE_FcHyfV3TQ"
      },
      "source": [
        "### Feature Scaling\n",
        "\n",
        "### *It is compulsory for deep learning*\n",
        "\n",
        "What is it? Feature scaling is the process of normalising the range of features in a dataset, in order for the ML model to interpret the features on the same scale. StandardScaler is the Scikit-learn function for standardisation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViCrE00rV8Sk"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zfEzkRVXIwF"
      },
      "source": [
        "## Part 2 - Building the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvdeScabXtlB"
      },
      "source": [
        "### Initializing the ANN\n",
        "\n",
        "Initializes our ANN as a sequence of layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dtrScHxXQox"
      },
      "source": [
        "ann = tf.keras.models.Sequential()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rP6urV6SX7kS"
      },
      "source": [
        "### Adding the input layer and the first hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bppGycBXYCQr"
      },
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
        "# units; the number of neurons we want to have in this hidden layer"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BELWAc_8YJze"
      },
      "source": [
        "### Adding the second hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JneR0u0sYRTd"
      },
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyNEe6RXYcU4"
      },
      "source": [
        "### Adding the output layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn3x41RBYfvY"
      },
      "source": [
        "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "# using the sigmoid one because we want a binary outcome\n",
        "# it gives the probability of whether each customer leaves the bank or not "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT4u2S1_Y4WG"
      },
      "source": [
        "## Part 3 - Training the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GWlJChhY_ZI"
      },
      "source": [
        "### Compiling the ANN\n",
        "\n",
        "Compiling it with an optimizer, loss and metrics --> \n",
        "We then compile the model with the compile function. This creates the neural network model by specifying the details of the learning process. The model hasn’t been trained yet. Right now we’re just declaring the optimizer to use and the loss function to minimize. The arguments for the compile function are defined as follows:\n",
        "*`optimizer:`* Which optimizer to use in order to minimize the loss function. There are a lot of different optimizers, most of them based on gradient descent. We will explore different optimizers in another tutorial. For now we will use the adam optimizer, which is the one people prefer to use by default. The 'adam' one is prefered because it can perform stochastic gradient descent, meaning that it will update the weights in order to reduce the loss error between our predictions and the real results.\n",
        "*`loss:`* The loss function to minimize. Since we’re building a binary 0/1 classifier, the loss function to minimize is binary_crossentropy. It is the way to compute the difference between the predictions and the real result. For non binary classification we would have used crossentropy.\n",
        "*(NOTE: When predicting more than two categories the activation function should not be sigmoid but softmax.) *\n",
        "*`metrics:`* Which metric to report statistics on, for classification problems we set this as accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG3RrwDXZEaS"
      },
      "source": [
        "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QR_G5u7ZLSM"
      },
      "source": [
        "### Training the ANN on the Training set\n",
        "\n",
        "The method to train whatever ML model, is always the same, the **fit** method, which also always takes the same parameters. The first one is the x_train--> the matrix of features of the training set, then y_train--> for the dependent variable of the training set.\n",
        "\n",
        "Also two more parameters: the **batch size** which gives exactly the number of predictions we want to have in the batch, compared to that same number of real results. The classic value of the batch size is 32. The batch size is a hyperparameter of gradient descent that controls the number of training samples to work through before the model’s internal parameters are updated.\n",
        "\n",
        "number of **epochs**: An epoch means training the neural network with all the training data for one cycle. In an epoch, we use all of the data exactly once. A forward pass and a backward pass together are counted as one pass: An epoch is made up of one or more batches, where we use a part of the dataset to train the neural network. The number of epochs is a hyperparameter of gradient descent that controls the number of complete passes through the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHZ-LKv_ZRb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6beafdb6-2df6-48ad-e5ea-88fb8e775865"
      },
      "source": [
        "ann.fit(X_train, y_train, batch_size = 32, epochs = 100)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "250/250 [==============================] - 4s 3ms/step - loss: 0.5166 - accuracy: 0.7960\n",
            "Epoch 2/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4770 - accuracy: 0.7960\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4469 - accuracy: 0.7960\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4338 - accuracy: 0.7960\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4273 - accuracy: 0.7960\n",
            "Epoch 6/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4222 - accuracy: 0.7960\n",
            "Epoch 7/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4174 - accuracy: 0.7960\n",
            "Epoch 8/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4103 - accuracy: 0.7960\n",
            "Epoch 9/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4017 - accuracy: 0.7960\n",
            "Epoch 10/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3930 - accuracy: 0.7960\n",
            "Epoch 11/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3859 - accuracy: 0.7960\n",
            "Epoch 12/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3810 - accuracy: 0.8340\n",
            "Epoch 13/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3775 - accuracy: 0.8476\n",
            "Epoch 14/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3750 - accuracy: 0.8491\n",
            "Epoch 15/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3724 - accuracy: 0.8534\n",
            "Epoch 16/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3702 - accuracy: 0.8537\n",
            "Epoch 17/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3686 - accuracy: 0.8555\n",
            "Epoch 18/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3669 - accuracy: 0.8556\n",
            "Epoch 19/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3655 - accuracy: 0.8570\n",
            "Epoch 20/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3649 - accuracy: 0.8584\n",
            "Epoch 21/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3630 - accuracy: 0.8580\n",
            "Epoch 22/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3616 - accuracy: 0.8564\n",
            "Epoch 23/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3606 - accuracy: 0.8602\n",
            "Epoch 24/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3596 - accuracy: 0.8620\n",
            "Epoch 25/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3587 - accuracy: 0.8614\n",
            "Epoch 26/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3577 - accuracy: 0.8605\n",
            "Epoch 27/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3561 - accuracy: 0.8618\n",
            "Epoch 28/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3556 - accuracy: 0.8621\n",
            "Epoch 29/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3545 - accuracy: 0.8605\n",
            "Epoch 30/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3537 - accuracy: 0.8610\n",
            "Epoch 31/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3534 - accuracy: 0.8610\n",
            "Epoch 32/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3525 - accuracy: 0.8619\n",
            "Epoch 33/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3515 - accuracy: 0.8610\n",
            "Epoch 34/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3512 - accuracy: 0.8627\n",
            "Epoch 35/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3500 - accuracy: 0.8630\n",
            "Epoch 36/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3497 - accuracy: 0.8621\n",
            "Epoch 37/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3493 - accuracy: 0.8621\n",
            "Epoch 38/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3481 - accuracy: 0.8640\n",
            "Epoch 39/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3481 - accuracy: 0.8629\n",
            "Epoch 40/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3476 - accuracy: 0.8618\n",
            "Epoch 41/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3472 - accuracy: 0.8636\n",
            "Epoch 42/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3465 - accuracy: 0.8633\n",
            "Epoch 43/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3457 - accuracy: 0.8619\n",
            "Epoch 44/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3459 - accuracy: 0.8635\n",
            "Epoch 45/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3457 - accuracy: 0.8612\n",
            "Epoch 46/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3449 - accuracy: 0.8633\n",
            "Epoch 47/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3449 - accuracy: 0.8621\n",
            "Epoch 48/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3449 - accuracy: 0.8633\n",
            "Epoch 49/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3439 - accuracy: 0.8637\n",
            "Epoch 50/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3438 - accuracy: 0.8637\n",
            "Epoch 51/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3433 - accuracy: 0.8635\n",
            "Epoch 52/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3432 - accuracy: 0.8645\n",
            "Epoch 53/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3430 - accuracy: 0.8651\n",
            "Epoch 54/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3432 - accuracy: 0.8644\n",
            "Epoch 55/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3423 - accuracy: 0.8648\n",
            "Epoch 56/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3423 - accuracy: 0.8645\n",
            "Epoch 57/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3419 - accuracy: 0.8662\n",
            "Epoch 58/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3413 - accuracy: 0.8643\n",
            "Epoch 59/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3415 - accuracy: 0.8633\n",
            "Epoch 60/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3417 - accuracy: 0.8658\n",
            "Epoch 61/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3411 - accuracy: 0.8666\n",
            "Epoch 62/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3412 - accuracy: 0.8649\n",
            "Epoch 63/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3406 - accuracy: 0.8661\n",
            "Epoch 64/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3401 - accuracy: 0.8651\n",
            "Epoch 65/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3402 - accuracy: 0.8631\n",
            "Epoch 66/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3404 - accuracy: 0.8644\n",
            "Epoch 67/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3398 - accuracy: 0.8641\n",
            "Epoch 68/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3393 - accuracy: 0.8661\n",
            "Epoch 69/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3398 - accuracy: 0.8646\n",
            "Epoch 70/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3391 - accuracy: 0.8652\n",
            "Epoch 71/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3394 - accuracy: 0.8633\n",
            "Epoch 72/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3390 - accuracy: 0.8654\n",
            "Epoch 73/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3394 - accuracy: 0.8658\n",
            "Epoch 74/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3389 - accuracy: 0.8659\n",
            "Epoch 75/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3388 - accuracy: 0.8648\n",
            "Epoch 76/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3382 - accuracy: 0.8661\n",
            "Epoch 77/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3382 - accuracy: 0.8641\n",
            "Epoch 78/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3380 - accuracy: 0.8635\n",
            "Epoch 79/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3382 - accuracy: 0.8664\n",
            "Epoch 80/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3379 - accuracy: 0.8662\n",
            "Epoch 81/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3375 - accuracy: 0.8655\n",
            "Epoch 82/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3379 - accuracy: 0.8648\n",
            "Epoch 83/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3377 - accuracy: 0.8635\n",
            "Epoch 84/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3377 - accuracy: 0.8654\n",
            "Epoch 85/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3379 - accuracy: 0.8643\n",
            "Epoch 86/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3375 - accuracy: 0.8641\n",
            "Epoch 87/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3378 - accuracy: 0.8629\n",
            "Epoch 88/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3370 - accuracy: 0.8661\n",
            "Epoch 89/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3370 - accuracy: 0.8646\n",
            "Epoch 90/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3371 - accuracy: 0.8662\n",
            "Epoch 91/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3368 - accuracy: 0.8644\n",
            "Epoch 92/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3369 - accuracy: 0.8665\n",
            "Epoch 93/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3371 - accuracy: 0.8661\n",
            "Epoch 94/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3368 - accuracy: 0.8648\n",
            "Epoch 95/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3363 - accuracy: 0.8664\n",
            "Epoch 96/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3366 - accuracy: 0.8651\n",
            "Epoch 97/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3359 - accuracy: 0.8648\n",
            "Epoch 98/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3364 - accuracy: 0.8654\n",
            "Epoch 99/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3362 - accuracy: 0.8649\n",
            "Epoch 100/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.3364 - accuracy: 0.8652\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faa602fa7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsuCZoU5u3Ds"
      },
      "source": [
        "Our accuracy around 86% means that out of 100 observations, we have 86 correct predictions. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJj5k2MxZga3"
      },
      "source": [
        "## Part 4 - Making the predictions and evaluating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84QFoqGYeXHL"
      },
      "source": [
        "### Predicting the result of a single observation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGRo3eacgDdC"
      },
      "source": [
        "**Homework**\n",
        "\n",
        "Use our ANN model to predict if the customer with the following informations will leave the bank: \n",
        "\n",
        "Geography: France\n",
        "\n",
        "Credit Score: 600\n",
        "\n",
        "Gender: Male\n",
        "\n",
        "Age: 40 years old\n",
        "\n",
        "Tenure: 3 years\n",
        "\n",
        "Balance: \\$ 60000\n",
        "\n",
        "Number of Products: 2\n",
        "\n",
        "Does this customer have a credit card ? Yes\n",
        "\n",
        "Is this customer an Active Member: Yes\n",
        "\n",
        "Estimated Salary: \\$ 50000\n",
        "\n",
        "So, should we say goodbye to that customer ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhU1LTgPg-kH"
      },
      "source": [
        "**Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d8IoCCkeWGL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3633265e-77bd-473b-f026-0b66c82ddf6c"
      },
      "source": [
        "print(ann.predict(sc.transform([[1, 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])) > 0.5)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[False]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGjx94g2n7OV"
      },
      "source": [
        "Therefore, our ANN model predicts that this customer stays in the bank!\n",
        "\n",
        "**Important note 1:** Notice that the values of the features were all input in a double pair of square brackets. That's because the \"predict\" method always expects a 2D array as the format of its inputs. And putting our values into a double pair of square brackets makes the input exactly a 2D array.\n",
        "\n",
        "**Important note 2:** Notice also that the \"France\" country was not input as a string in the last column but as \"1, 0, 0\" in the first three columns. That's because of course the predict method expects the one-hot-encoded values of the state, and as we see in the first row of the matrix of features X, \"France\" was encoded as \"1, 0, 0\". And be careful to include these values in the first three columns, because the dummy variables are always created in the first columns.\n",
        "\n",
        "**Important note 3:** why > 0.5? we choose a threshold of  0.5 to say that if that predicted probability is larger than 0.5, we will consider the final result to be 1, meaning that there is more than 50 percent chance that the predicted outcome is one. And however, if the predicted probability that the customer leaves the bank is below 0.5, we will consider it to be zero. Of course, you can choose a different value of the threshold, especially when you have critical outcome for a critical decision and in that case, you can, for example, increase the threshold.\n",
        "\n",
        "**Important note 4:** remember to apply scaling from your sc object because your artificial neural network was trained with scaled values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7yx47jPZt11"
      },
      "source": [
        "### Predicting the Test set results\n",
        "\n",
        "Back to our model now. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIyEeQdRZwgs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76c3b544-f0ee-4773-ce2e-9fa9db58701a"
      },
      "source": [
        "y_pred = ann.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0]\n",
            " [0 1]\n",
            " [0 0]\n",
            " ...\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0oyfLWoaEGw"
      },
      "source": [
        "### Making the Confusion Matrix\n",
        "\n",
        "checking our results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci6K_r6LaF6P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b17e1430-3e81-4591-b4c0-259737cd65b1"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1523   72]\n",
            " [ 210  195]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.859"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1jw7lrez5Xh"
      },
      "source": [
        "We have 1523 correct predictions that the customer stays in the bank, 72 incorect predictions that the customer leaves the bank, 210 correct predictions that the customer will leave the bank and 195 incorrect predictions that the customer stays in the bank. \n",
        "Accuracy of a 85,9% - almost 86% is a very decent accuracy "
      ]
    }
  ]
}